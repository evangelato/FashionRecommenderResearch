{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fad6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Library import readdata\n",
    "from Library import readdata_time\n",
    "from Library import evaluation_F1\n",
    "from Library import evaluation_NDCG\n",
    "from Library import save_result\n",
    "from Library import read_feature\n",
    "from numpy import *\n",
    "#from LatentFactor import LatentFactorModel\n",
    "import xlwt\n",
    "import time\n",
    "import json\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70db59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameter setting\n",
    "dataset = 5                         # Datasets selecting 0 to 5 for 'All', '_Women', '_Men', '_CLothes', '_Shoes', '_Jewelry' respectively\n",
    "eta = 0.03                          # learning rate\n",
    "I = 200                             # length of latent feature\n",
    "J = 100                             # length of latent feature\n",
    "top_k = [5, 10, 20, 50, 100]        # number to recommend\n",
    "batch_size_train = 5000             # batch size for traing\n",
    "batch_size_test = 1000              # batch size for tessing\n",
    "lambda_c = 0.1                      # weighting parameter for couple matrices\n",
    "lambda_r = 1.5                      # regularization coefficient\n",
    "vali_test = 0                       # 0 for validate set,1 for test set\n",
    "feat = [3]                          # feature selecting, 0 for CNN, 1 for AES, 2 for CH, 3 for CNN+AES\n",
    "feature_length = 1000               # length of feature\n",
    "#epoch = 200                         # number to iteration\n",
    "epoch = 5\n",
    "sample_rate = 5                     # sample sample_rate negative samples for each positive item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b536c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(dataset):\n",
    "    # to load features\n",
    "    feat_list = ['CNN', 'AES', 'CH', 'CNN_AES']             # feature list\n",
    "    F = read_feature(feat_list[feat[0]], dataset, Q)\n",
    "    for i in range(1, len(feat)):\n",
    "        F = np.hstack((F, read_feature(feat_list[feat[i]], dataset, Q)))\n",
    "    return F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e7cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order(Order, length):\n",
    "    # combining several recommendation lists into one, for tensor-based model\n",
    "    order = []\n",
    "    ind = 0\n",
    "    while len(order) <= length:\n",
    "        for line in Order:\n",
    "            if not line[ind] in order:\n",
    "                order.append(line[ind])\n",
    "        ind += 1\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04eafe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DCFA(U, Vu, Vt, T, M, N, F):\n",
    "    # test the effectiveness\n",
    "    U = mat(U)\n",
    "    Vu = mat(Vu)\n",
    "    Vt = mat(Vt)\n",
    "    T = mat(T)\n",
    "    F = mat(F)\n",
    "    M = mat(M)\n",
    "    N = mat(N)\n",
    "    k_num = len(top_k)\n",
    "    # k_num-long lists to record F1 and NDCG\n",
    "    F1 = np.zeros(k_num)\n",
    "    NDCG = np.zeros(k_num)\n",
    "    num_item = len(Test)\n",
    "\n",
    "    # choose batch_size_test test samples randomly\n",
    "    for i in range(batch_size_test):\n",
    "        j = int(math.floor(num_item * random.random()))\n",
    "        # test data: [u, [i, i, i, i], [r, r, r]], where u, i, r are for user, item, time, respectively\n",
    "        u = Test[j][0]\n",
    "        test_item = Test[j][1]\n",
    "        # score for all users\n",
    "        Order = []\n",
    "        for r in Test[j][2]:\n",
    "            # for each r, score all items\n",
    "            UV = U[u] * Vu.T + M[u] * F.T\n",
    "            VT = T[r] * Vt.T + N[r] * F.T\n",
    "            UV = np.array(UV.tolist()[0])\n",
    "            VT = np.array(VT.tolist()[0])\n",
    "            score = (UV * VT).tolist()\n",
    "            # order\n",
    "            b = zip(score, range(len(score)))\n",
    "            b = sorted(b, key=lambda x: x[0])\n",
    "            order = [x[1] for x in b]\n",
    "            order.reverse()\n",
    "            Order.append(order)\n",
    "        # train samples\n",
    "        train_positive = train_data_aux[u][0]\n",
    "        # we have len(train_data_aux[u][1]) k-length recommendation lists for each user,\n",
    "        # to compare fairly with other baselines, we combine len(train_data_aux[u][1]) k-length list to one k-length lists for each user\n",
    "        # we will remove at most len(train_positive) train samples from order, so we return k+len(train_positive) items\n",
    "        order = get_order(Order, top_k[-1] + len(train_positive))\n",
    "        # remove the train samples from the recommendations\n",
    "        for item in train_positive:\n",
    "            try:\n",
    "                order.remove(item)\n",
    "            except:\n",
    "                continue\n",
    "        # we also remove the train samples from test samples\n",
    "        test_item = list(set(test_item) - set(train_positive))\n",
    "        # test F1 and NDCG for each k\n",
    "        for i in range(len(top_k)):\n",
    "            F1[i] += evaluation_F1(order, top_k[i], test_item)\n",
    "            NDCG[i] += evaluation_NDCG(order, top_k[i], test_item)\n",
    "    # calculate the average\n",
    "    F1 = (F1 / batch_size_test).tolist()\n",
    "    NDCG = (NDCG / batch_size_test).tolist()\n",
    "    return F1, NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import sigmoid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf9e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DCFA(eta):\n",
    "    # train the model\n",
    "    # initialization\n",
    "    U = np.array([np.array([(random.random() / math.sqrt(I)) for j in range(I)]) for i in range(P)])\n",
    "    Vu = np.array([np.array([(random.random() / math.sqrt(I)) for j in range(I)]) for i in range(Q)])\n",
    "    Vt = np.array([np.array([(random.random() / math.sqrt(J)) for j in range(J)]) for i in range(Q)])\n",
    "    T = np.array([np.array([(random.random() / math.sqrt(J)) for j in range(J)]) for i in range(R)])\n",
    "\n",
    "    M = np.array([np.array([(random.random() / math.sqrt(K)) for j in range(K)]) for i in range(P)])\n",
    "    N = np.array([np.array([(random.random() / math.sqrt(K)) for j in range(K)]) for i in range(R)])\n",
    "    e = 10**10\n",
    "\n",
    "    # output a result without training\n",
    "    print('iteration ', 0,)\n",
    "    [F1, NDCG] = test_DCFA(U, Vu, Vt, T, M, N, F)\n",
    "    Fmax = 0\n",
    "    if F1[0] > Fmax:\n",
    "        Fmax = F1[0]\n",
    "    print(Fmax, 'F1: ', F1, '  ', 'NDCG1: ', NDCG)\n",
    "    # save to the .xls file\n",
    "    save_result([' '], [''] * len(top_k), [''] * len(top_k), path_excel)\n",
    "    save_result('metric', ['F1'] * len(top_k), ['NDCG'] * len(top_k), path_excel)\n",
    "    save_result('Top_k', top_k, top_k, path_excel)\n",
    "    save_result([' '], [''] * len(top_k), [''] * len(top_k), path_excel)\n",
    "    save_result('iteration ' + str(0), F1, NDCG, path_excel)\n",
    "\n",
    "    # the number of train samples\n",
    "    Re = len(train_data)\n",
    "    # split the train samples with a step of batch_size_train\n",
    "    bs = list(range(0, Re, batch_size_train))\n",
    "    bs.append(Re)\n",
    "\n",
    "    for ep in range(0, epoch): # while not converged && iter < iter_max do\n",
    "        print('iteration ', ep + 1,)\n",
    "        eta = eta * 0.99\n",
    "        # iterate all train samples in one epoch\n",
    "        for i in range(0, len(bs) - 1):\n",
    "        # for each batch do\n",
    "            if abs(U.sum()) < e:\n",
    "                # initialize dU and dC to record the gradient\n",
    "                dU = np.zeros((P, I))\n",
    "                dVu = np.zeros((Q, I))\n",
    "                dVt = np.zeros((Q, J))\n",
    "                dT = np.zeros((R, J))\n",
    "\n",
    "                dM = np.zeros((P, K))\n",
    "                dN = np.zeros((R, K))\n",
    "                for re in range(bs[i], bs[i + 1]):\n",
    "                # for each record in current batch do\n",
    "                    # train sample: [u, i, r]\n",
    "                    p = train_data[re][0]\n",
    "                    qi = train_data[re][1]\n",
    "                    r = train_data[re][2]\n",
    "\n",
    "                    UV = np.dot(U[p], Vu[qi])\n",
    "                    VT = np.dot(Vt[qi], T[r])\n",
    "                    MDF = np.dot(M[p], F[qi])\n",
    "                    NEF = np.dot(N[r], F[qi])\n",
    "\n",
    "                    Bi = UV + MDF\n",
    "                    Ci = VT + NEF\n",
    "                    Ai = Bi * Ci\n",
    "\n",
    "                    num = 0\n",
    "                    # choose sample_rate negative items, and calculate the gradient\n",
    "                    while num < sample_rate:\n",
    "                    # select 5 non-observed items qâ€² randomly\n",
    "                        qj = int(random.uniform(0, Q))\n",
    "                        if (not qj in train_data_aux[p][0]) and (not qj in train_time_aux[r][1]):\n",
    "                            num += 1\n",
    "                            UV = np.dot(U[p], Vu[qj])\n",
    "                            VT = np.dot(Vt[qj], T[r])\n",
    "                            MDF = np.dot(M[p], F[qj])\n",
    "                            NEF = np.dot(N[r], F[qj])\n",
    "\n",
    "                            Bj = UV + MDF\n",
    "                            Cj = VT + NEF\n",
    "                            Aj = Bj * Cj\n",
    "\n",
    "                            Bij = Bi - Bj\n",
    "                            Cij = Ci - Cj\n",
    "                            Aij = Ai - Aj\n",
    "\n",
    "                            dU[p] += sigmoid(-Aij) * (Ci * Vu[qi] - Cj * Vu[qj]) + lambda_c * sigmoid(-Bij) * (Vu[qi] - Vu[qj])\n",
    "                            dVu[qi] += sigmoid(-Aij) * Ci * U[p] + lambda_c * sigmoid(-Bij) * U[p]\n",
    "                            dVu[qj] -= sigmoid(-Aij) * Cj * U[p] + lambda_c * sigmoid(-Bij) * U[p]\n",
    "                            dM[p] += sigmoid(-Aij) * (Ci * F[qi] - Cj * F[qj]) + lambda_c * sigmoid(-Bij) * (F[qi] - F[qj])\n",
    "                            dVt[qi] += sigmoid(-Aij) * Bi * T[r] + lambda_c * sigmoid(-Cij) * T[r]\n",
    "                            dVt[qj] -= sigmoid(-Aij) * Bj * T[r] + lambda_c * sigmoid(-Cij) * T[r]\n",
    "                            dT[r] += sigmoid(-Aij) * (Bi * Vt[qi] - Bj * Vt[qj]) + lambda_c * sigmoid(-Cij) * (Vt[qi] - Vt[qj])\n",
    "                            dN[r] += sigmoid(-Aij) * (Bi * F[qi] - Bj * F[qj]) + lambda_c * sigmoid(-Cij) * (F[qi] - F[qj])\n",
    "\n",
    "                # update the matrices\n",
    "                U += eta * (dU - lambda_r * U)\n",
    "                Vu += eta * (dVu - lambda_r * Vu)\n",
    "                Vt += eta * (dVt - lambda_r * Vt)\n",
    "                T += eta * (dT - lambda_r * T)\n",
    "                M += eta * (dM - lambda_r * M)\n",
    "                N += eta * (dN - lambda_r * N)\n",
    "\n",
    "        if abs(U.sum()) < e:\n",
    "            [F1, NDCG] = test_DCFA(U, Vu, Vt, T, M, N, F)\n",
    "            if F1[0] > Fmax:\n",
    "                Fmax = F1[0]\n",
    "            print(Fmax, 'F1: ', F1, '  ', 'NDCG1: ', NDCG)\n",
    "            save_result('iteration ' + str(ep + 1), F1, NDCG, path_excel)\n",
    "        else:\n",
    "            break\n",
    "        #return U, Vu, Vt, T, M, N\n",
    "    if abs(U.sum()) < e:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dec32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameter():\n",
    "    # record the parameters\n",
    "    dataset_list = ['all', '_Women', '_Men', '_CLothes', '_Shoes', '_Jewelry']\n",
    "    excel = xlwt.Workbook()\n",
    "    table = excel.add_sheet('A Test Sheet')\n",
    "    table.write(0, 0, 'model')\n",
    "    table.write(0, 2, 'DCFA')\n",
    "    table.write(1, 0, 'dataset')\n",
    "    table.write(1, 2, dataset_list[dataset])\n",
    "    table.write(2, 0, 'eta')\n",
    "    table.write(2, 2, eta)\n",
    "    table.write(3, 0, 'I')\n",
    "    table.write(3, 2, I)\n",
    "    table.write(4, 0, 'J')\n",
    "    table.write(4, 2, J)\n",
    "    table.write(5, 0, 'top_k')\n",
    "    for i in range(len(top_k)):\n",
    "        table.write(5, 2 + i, top_k[i])\n",
    "    table.write(6, 0, 'batch_size_train')\n",
    "    table.write(6, 2, batch_size_train)\n",
    "    table.write(7, 0, 'batch_size_test')\n",
    "    table.write(7, 2, batch_size_test)\n",
    "    table.write(8, 0, 'lambda_c')\n",
    "    table.write(8, 2, lambda_c)\n",
    "    table.write(9, 0, 'lambda_r')\n",
    "    table.write(9, 2, lambda_r)\n",
    "    table.write(10, 0, 'vali_test')\n",
    "    table.write(10, 2, vali_test)\n",
    "    table.write(11, 0, 'feat')\n",
    "    for i in range(len(feat)):\n",
    "        table.write(11, 2 + i, feat[i])\n",
    "    table.write(12, 0, 'fea_len')\n",
    "    table.write(12, 2, feature_length)\n",
    "    table.write(13, 0, 'epoch')\n",
    "    table.write(13, 2, epoch)\n",
    "    table.write(17, 0, ' ')\n",
    "\n",
    "    excel.save(path_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aee46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameter():\n",
    "    print('model', 'DCFA')\n",
    "    print('dataset', dataset)\n",
    "    print('eta', eta)\n",
    "    print('I', I) \n",
    "    print('J', J) \n",
    "    print('top_k', top_k)\n",
    "    print('batch_size_train', batch_size_train)\n",
    "    print('batch_size_test', batch_size_test)\n",
    "    print('lambda_c', lambda_c)\n",
    "    print('lambda_r', lambda_r)\n",
    "    print('vali_test', vali_test) \n",
    "    print('feat', feat) \n",
    "    print('feature_length', feature_length) \n",
    "    print('epoch', epoch)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee3a24",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model DCFA\n",
      "dataset 5\n",
      "eta 0.03\n",
      "I 200\n",
      "J 100\n",
      "top_k [5, 10, 20, 50, 100]\n",
      "batch_size_train 5000\n",
      "batch_size_test 1000\n",
      "lambda_c 0.1\n",
      "lambda_r 1.5\n",
      "vali_test 0\n",
      "feat [3]\n",
      "feature_length 1000\n",
      "epoch 5\n",
      "iteration  0\n",
      "0.0006190476190476103 F1:  [0.0006190476190476103, 0.001047785547785533, 0.0008358742706568667, 0.000935171746492489, 0.0009258883220395879]    NDCG1:  [0.000470365282770005, 0.0005919064335373652, 0.00048700744085603193, 0.0004926911363325911, 0.0004815457923808024]\n",
      "iteration  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:22:47.751771: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010494322344322187 F1:  [0.010494322344322187, 0.010239332889332726, 0.008074121997165331, 0.005368427199857196, 0.003817693112923568]    NDCG1:  [0.008170980716041583, 0.0070044296368740626, 0.005503662068618826, 0.003785994025856993, 0.002754895196102557]\n",
      "iteration  2\n"
     ]
    }
   ],
   "source": [
    "'''*************************main function****************************'''\n",
    "'''*************************main function****************************'''\n",
    "for i in range(1):\n",
    "    # datasets\n",
    "    dataset_list = ['', '_Women', '_Men', '_CLothes', '_Shoes', '_Jewelry']\n",
    "    # load data\n",
    "    [train_data, train_data_aux, validate_data, test_data, P, Q] = readdata(dataset_list[dataset])\n",
    "    # load data for tensor factorization\n",
    "    [train_record_aux, train_time_aux, R] = readdata_time(dataset_list[dataset])\n",
    "    # load features\n",
    "    F = get_feature(dataset_list[dataset])\n",
    "    K = len(F[0])\n",
    "    # select test set or validation set\n",
    "    if vali_test == 0:\n",
    "        Test = validate_data\n",
    "    else:\n",
    "        Test = test_data\n",
    "\n",
    "    #for j in range(1):\n",
    "    path_excel = 'experiment_result/' + dataset_list[dataset] + '_DCFA_' + str(int(time.time())) + str(int(random.uniform(100,900))) + '.xls'\n",
    "    save_parameter()\n",
    "    print_parameter()\n",
    "    train_DCFA(eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}